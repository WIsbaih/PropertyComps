{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc3ef0-49e1-4ba2-a275-eaa902dcb651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model training complete using properties.json.\n",
      "üîç Preview of clustered properties (with assigned cluster labels):\n",
      "    id                   address  cluster\n",
      "   367       463 Conservatory Dr        4\n",
      "163443   463 Conservatory Drive         4\n",
      "   378            311 Janette St        4\n",
      "130023       311 Janette Street         2\n",
      "  2782              4056 Bath Rd        4\n",
      "  2783     786 HIGH GATE PARK Dr        4\n",
      "138739 786 HIGH GATE PARK Drive         4\n",
      "  2763            784 Downing St        4\n",
      "146595       784 Downing Street         2\n",
      "   163          593 Roosevelt Dr        4\n",
      "\n",
      "üìä Cluster distribution (how many properties in each cluster):\n",
      "cluster\n",
      "0      2\n",
      "1      3\n",
      "2     17\n",
      "3      2\n",
      "4    122\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ü§ñ KNN predicted clusters for first 5 entries:\n",
      "[4 4 4 2 4]\n",
      "üíæ Clustered data saved to:\n",
      " - ../data/properties_clustered.csv\n",
      " - ../data/properties_clustered.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load properties from JSON file\n",
    "with open(\"../data/properties.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    properties = json.load(f)\n",
    "\n",
    "# Remove duplicates by ID\n",
    "unique_props = {}\n",
    "for prop in properties:\n",
    "    prop_id = prop.get(\"id\")\n",
    "    if prop_id:\n",
    "        unique_props[prop_id] = prop\n",
    "\n",
    "df = pd.DataFrame(unique_props.values())\n",
    "\n",
    "# Fill missing values\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == \"object\":\n",
    "        df[column] = df[column].fillna(\"\")\n",
    "    elif pd.api.types.is_numeric_dtype(df[column]):\n",
    "        df[column] = df[column].fillna(0)\n",
    "    else:\n",
    "        df[column] = df[column].fillna(\"unknown\")\n",
    "\n",
    "# --- TEXT CLUSTERING ---\n",
    "# Select or combine text columns\n",
    "text_columns = df.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "if \"description\" in df.columns:\n",
    "    text_column = \"description\"\n",
    "elif len(text_columns) > 0:\n",
    "    text_column = text_columns[0]\n",
    "else:\n",
    "    df[\"combined_text\"] = df.astype(str).agg(\" \".join, axis=1)\n",
    "    text_column = \"combined_text\"\n",
    "\n",
    "# TF-IDF vectorization and KMeans clustering\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=100)\n",
    "X_text = vectorizer.fit_transform(df[text_column])\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init='auto')\n",
    "kmeans.fit(X_text)\n",
    "df[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "# Save text-based models\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(vectorizer, \"../models/vectorizer.joblib\")\n",
    "joblib.dump(kmeans, \"../models/cluster_model.joblib\")\n",
    "\n",
    "# --- KNN on Numeric Features ---\n",
    "numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "X_numeric = df[numeric_columns]\n",
    "\n",
    "# Standardize + KNN pipeline\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Use clusters as labels for supervised KNN training\n",
    "knn_pipeline.fit(X_numeric, df[\"cluster\"])\n",
    "\n",
    "# Save KNN pipeline\n",
    "joblib.dump(knn_pipeline, \"../models/knn_model.joblib\")\n",
    "\n",
    "print(\"‚úÖ Model training complete using properties.json.\")\n",
    "\n",
    "print(\"üîç Preview of clustered properties (with assigned cluster labels):\")\n",
    "print(df[[\"id\", text_column, \"cluster\"]].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìä Cluster distribution (how many properties in each cluster):\")\n",
    "print(df[\"cluster\"].value_counts().sort_index())\n",
    "\n",
    "sample_X = df[numeric_columns].head(5)\n",
    "predicted_clusters = knn_pipeline.predict(sample_X)\n",
    "print(\"\\nü§ñ KNN predicted clusters for first 5 entries:\")\n",
    "print(predicted_clusters)\n",
    "\n",
    "# Save clustered data to CSV and JSON\n",
    "df.to_csv(\"../data/properties_clustered.csv\", index=False)\n",
    "\n",
    "print(\"üíæ Clustered data saved to:\")\n",
    "print(\" - ../data/properties_clustered.csv\")\n",
    "print(\" - ../data/properties_clustered.json\")\n",
    "#test\n",
    "columns_to_save = [\"id\", text_column, \"cluster\"] + list(numeric_columns)\n",
    "df[columns_to_save].to_csv(\"../data/properties_clustered_simple.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950132f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
